# Quick Reference Card - Web Scraping Enhancement
## One-Page Cheat Sheet

**Project**: Noticias Pachuca | **Date**: Oct 21, 2025 | **Status**: Ready to Implement

---

## üéØ Current State ‚Üí Target State

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Success Rate | 70% | 92%+ | +22% |
| Cloudflare Bypass | 0% | 87%+ | +87% |
| Extraction Time | 5-10s | 3-5s | 50% faster |
| Monthly Cost | $0 | $50-150 | $150 budget |

---

## ‚ö° Quick Wins (5.5 hours total) - DO THESE FIRST!

### 1. Update User-Agents (30 min)
```typescript
// In noticias-scraping.service.ts
private readonly userAgents = [
  'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/131.0.0.0',
  'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) Chrome/131.0.0.0',
  'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:133.0) Firefox/133.0',
];
```

### 2. Add Sec-CH-UA Headers (1 hour)
```typescript
headers: {
  'sec-ch-ua': '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
  'sec-ch-ua-mobile': '?0',
  'sec-ch-ua-platform': '"Windows"',
}
```

### 3. Install Rebrowser (2 hours)
```bash
npm install rebrowser-puppeteer-core
# In puppeteer-manager.service.ts
import puppeteer from 'rebrowser-puppeteer-core';
process.env.REBROWSER_PATCHES_RUNTIME_FIX_MODE = 'addBinding';
```

### 4. Add Rate Limiting (2 hours)
```bash
npm install bottleneck
# Use limiter.wrap() around scraping functions
```

**Expected Impact**: +10-15% success rate immediately

---

## üìã Implementation Checklist

### Phase 1: Setup (1-2 days)
- [ ] Backup MongoDB
- [ ] `git checkout -b feature/advanced-anti-detection`
- [ ] `npm install rebrowser-puppeteer-core crawlee bottleneck`
- [ ] Add .env variables (proxies, CAPTCHA keys)

### Phase 2: Build Core (3-5 days)
- [ ] Create `/src/scraping/scraping.module.ts`
- [ ] Build `AdvancedScrapingService` (fallback chain)
- [ ] Build `ProxyConfigurationService` (tiered rotation)
- [ ] Build `FingerprintGeneratorService` (modern headers)
- [ ] Build `RateLimiterService` (Bottleneck)
- [ ] Build `ScrapingMetricsService` (tracking)

### Phase 3: Integration (2-3 days)
- [ ] Modify `NoticiasScrapingService` (delegate to Advanced)
- [ ] Modify `NewsWebsiteService` (delegate to Advanced)
- [ ] Update `noticias.module.ts` (import ScrapingModule)
- [ ] Update `generator-pro.module.ts` (import ScrapingModule)

### Phase 4: Test (2-3 days)
- [ ] Unit tests (each service)
- [ ] Integration test (full flow)
- [ ] Real-world test (Cloudflare site)
- [ ] Load test (1000 URLs)

### Phase 5: Deploy (1-2 days)
- [ ] Deploy to staging
- [ ] Run full test suite
- [ ] Monitor 24 hours
- [ ] Deploy to production

---

## üîë Key Files

### Modify These (7 files)
```
src/noticias/services/noticias-scraping.service.ts
src/generator-pro/services/news-website.service.ts
src/modules/reports/services/puppeteer-manager.service.ts
src/noticias/noticias.module.ts
src/generator-pro/generator-pro.module.ts
src/app.module.ts
package.json
```

### Create These (9 files)
```
src/scraping/scraping.module.ts
src/scraping/services/advanced-scraping.service.ts
src/scraping/services/proxy-configuration.service.ts
src/scraping/services/fingerprint-generator.service.ts
src/scraping/services/captcha-solver.service.ts
src/scraping/services/rate-limiter.service.ts
src/scraping/services/scraping-metrics.service.ts
src/scraping/dto/scraper-config.dto.ts
src/scraping/interfaces/scraping.interfaces.ts
```

---

## üí∞ Cost Breakdown (Monthly)

### Budget Option ($10-30/month)
- Crawlee + Rebrowser (free)
- ProxyWing ($2.50/GB) ‚âà $10-20
- NoCaptchaAI ($0.14/1000) ‚âà $5-10
- **Total**: $15-30/month
- **For**: Testing, small-scale (< 50K requests/month)

### Production Option ($50-150/month) ‚≠ê RECOMMENDED
- Crawlee + Rebrowser (free)
- Smartproxy ($3.50/GB) ‚âà $40-80
- 2Captcha ($0.50/1000) ‚âà $10-20
- ScraperAPI fallback ($49/month) ‚âà $0-50
- **Total**: $50-150/month
- **For**: Production, 100K-500K requests/month

### Enterprise Option ($300+/month)
- ScraperAPI Enterprise ($299/month)
- **Total**: $300-1000/month
- **For**: Heavy scraping, DataDome sites

---

## üîß Environment Variables

```bash
# Proxies (Tiered)
DATACENTER_PROXY_URLS=http://user:pass@proxy1.com:8080,http://user:pass@proxy2.com:8080
RESIDENTIAL_PROXY_URLS=http://user:pass@residential.com:8080
MOBILE_PROXY_URLS=http://user:pass@mobile.com:8080

# CAPTCHA
TWOCAPTCHA_API_KEY=your_key_here
NOCAPTCHAAI_API_KEY=your_key_here

# ScraperAPI (fallback)
SCRAPERAPI_KEY=your_key_here

# Puppeteer
MAX_CONCURRENT_BROWSERS=5
PUPPETEER_HEADLESS=true

# Rate Limiting
DEFAULT_RATE_LIMIT=30
ADAPTIVE_RATE_LIMITING=true
```

---

## üìä Proxy Strategy (Tiered Escalation)

```
Attempt 1: No Proxy (Free, Fast)
    ‚Üì FAIL
Attempt 2: Datacenter Proxy ($0.001/req, Fast)
    ‚Üì FAIL (Cloudflare)
Attempt 3: Residential Proxy ($0.004/req, Moderate)
    ‚Üì FAIL (DataDome)
Attempt 4: Mobile Proxy ($0.012/req, Slow)
    ‚Üì FAIL (Last Resort)
Attempt 5: ScraperAPI ($0.01/req, Guaranteed)
```

**Smart Learning**: After 1 week, system auto-selects best tier per domain

---

## üéØ Success Metrics to Track

**Dashboard Metrics**:
- Overall success rate (target: 90%+)
- Cloudflare bypass rate (target: 80%+)
- Cost per extraction (target: < $0.002)
- Proxy health (healthy proxies %)
- CAPTCHA solve rate (target: 95%+)

**Alert Triggers**:
- üî¥ Domain failure rate > 50%
- ‚ö†Ô∏è Proxy pool < 3 healthy proxies
- üü° Monthly cost > 70% of budget

---

## üêõ Troubleshooting

### Issue: Still getting Cloudflare block
**Fix**:
1. Verify rebrowser env vars set
2. Use residential proxy (not datacenter)
3. Check User-Agent matches Sec-CH-UA

### Issue: High CAPTCHA costs
**Fix**:
1. Use residential/mobile proxies (reduces CAPTCHAs)
2. Increase cache TTL (reduce requests)
3. Blacklist high-CAPTCHA sites (use ScraperAPI)

### Issue: Slow extraction (> 10s)
**Fix**:
1. Check proxy latency (switch if > 2s)
2. Verify browser pool not full (increase MAX_CONCURRENT_BROWSERS)
3. Use Cheerio for static sites (faster than Puppeteer)

---

## üìû Where to Get Help

**Full Analysis**: `SCRAPING_ARCHITECTURE_ANALYSIS.md` (47 pages)
**Implementation Guide**: `ANTI_DETECTION_INTEGRATION_PLAN.md` (25 pages)
**Visual Diagrams**: `SCRAPING_FLOW_DIAGRAMS.md` (20 pages)
**This Summary**: `ANALYSIS_SUMMARY.md`

**External Docs**:
- Rebrowser: https://github.com/rebrowser/rebrowser-patches
- Crawlee: https://crawlee.dev
- ScraperAPI: https://www.scraperapi.com
- 2Captcha: https://2captcha.com

---

## üöÄ Recommended Next Steps

### Option A: Quick Start (5.5 hours)
1. Implement 4 Quick Wins above
2. Test on Cloudflare site
3. Measure improvement
4. Decide on full implementation

### Option B: Full Implementation (8-12 weeks)
1. Follow Phase 1-5 checklist
2. Budget: $50-150/month
3. Expected: 92%+ success rate

### Option C: Hybrid (Start Small)
1. Implement core services (Phase 1-2)
2. Test with 1-2 problem domains
3. Scale up based on results

**Recommendation**: Start with Option A (Quick Wins), then move to Option B if satisfied.

---

## ‚úÖ Definition of Done

**Implementation Complete When**:
- [ ] Overall success rate ‚â• 85%
- [ ] Cloudflare bypass rate ‚â• 70%
- [ ] Average extraction time ‚â§ 5 seconds
- [ ] Monthly cost within budget ($50-150)
- [ ] Monitoring dashboard deployed
- [ ] Alerts configured
- [ ] Documentation updated
- [ ] Team trained

---

## üìà Expected Timeline

**Quick Wins**: 5.5 hours
**Full Implementation**: 8-12 weeks
- Phase 1 (Setup): 1-2 days
- Phase 2 (Build): 3-5 days
- Phase 3 (Integration): 2-3 days
- Phase 4 (Testing): 2-3 days
- Phase 5 (Deploy): 1-2 days
- Phase 6 (Optimize): Ongoing

---

**Keep this document handy during implementation!**

**Last Updated**: October 21, 2025
**Project**: Noticias Pachuca
**Analyst**: Backend Architect (Jarvis)
