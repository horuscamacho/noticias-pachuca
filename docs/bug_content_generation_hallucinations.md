# Bug: Content Generation AI Hallucinations - Inferencias sin contexto

**Fecha:** 13 octubre 2025
**Reportado por:** Coyotito
**Severidad:** ALTA
**Archivo afectado:** `packages/api-nueva/src/content-ai/services/content-generation.service.ts` (lÃ­neas 873-1038)

---

## ğŸ› DescripciÃ³n del Problema

El modelo de generaciÃ³n de contenido estÃ¡ realizando **inferencias basadas en su conocimiento de entrenamiento** en lugar de adherirse estrictamente a los hechos presentados en la noticia original.

### Ejemplo del Bug

**Input (noticia original):**
```
La presidenta Claudia Sheinbaum afirmÃ³ este lunes que las autoridades no esperaban las lluvias tan intensas...
```

**Output generado (INCORRECTO):**
```
Durante una conferencia de prensa celebrada este lunes, la jefa de Gobierno de la Ciudad de MÃ©xico, Claudia Sheinbaum, abordÃ³ el impacto...
```

### Por quÃ© es un problema

1. **DesinformaciÃ³n**: El modelo dice "jefa de Gobierno" cuando la noticia claramente dice "presidenta"
2. **Conocimiento desactualizado**: El modelo (GPT-4o-mini con cutoff 2018) no sabe que Sheinbaum ya es presidenta
3. **Falta de grounding**: El prompt no fuerza suficientemente al modelo a usar SOLO los hechos del input
4. **PÃ©rdida de credibilidad**: Los lectores detectarÃ¡n informaciÃ³n incorrecta

---

## ğŸ”¬ AnÃ¡lisis TÃ©cnico

### InvestigaciÃ³n de Mejores PrÃ¡cticas 2025

Basado en investigaciÃ³n de Ãºltimas tÃ©cnicas para prevenir alucinaciones en LLMs:

#### 1. **Source-Aware Prompting** â­ (MÃ¡s efectiva)
```
"Usa ÃšNICAMENTE informaciÃ³n del texto proporcionado. Si algo no estÃ¡ en el texto, NO lo menciones."
```

#### 2. **Grounding Estricto con Prohibiciones ExplÃ­citas**
```
âŒ NO uses tu conocimiento previo
âŒ NO hagas suposiciones
âŒ NO infiera contextos que no estÃ¡n en el texto
âœ… SOLO usa hechos textuales del input
```

#### 3. **Chain-of-Verification (CoVe)**
Hacer que el modelo verifique su output contra el input antes de responder.

#### 4. **Reflective Prompting**
```
"Antes de responder, verifica que CADA afirmaciÃ³n estÃ© en el texto original."
```

#### 5. **"According to" Framing**
Forzar frases como "SegÃºn la noticia...", "El texto indica...", "De acuerdo con..."

---

## ğŸ“Š ComparaciÃ³n: Prompt Actual vs Prompt Mejorado

### âŒ Problema en el Prompt Actual

El prompt actual (lÃ­neas 873-1038) tiene:
- âœ… MUCHAS instrucciones sobre creatividad y extensiÃ³n
- âœ… Buenas instrucciones sobre estructura y formato
- âŒ POCAS instrucciones sobre fidelidad factual
- âŒ NO prohibe explÃ­citamente inferencias
- âŒ NO pide verificaciÃ³n contra la fuente

**Fragmento actual:**
```typescript
const optimizedPrompt = `Eres Jarvis, el asistente editorial de Pachuca Noticias...

ğŸ“ REGLAS PARA CONTENIDO EXTENSO:
EXTENSIÃ“N MÃNIMA OBLIGATORIA: 800-1200 palabras

ESTRUCTURA DETALLADA (distribuciÃ³n de palabras):
1. LEAD/ENTRADA (100-150 palabras)
2. DESARROLLO CONTEXTUAL (200-300 palabras)
3. CUERPO PRINCIPAL (300-400 palabras)
...
```

**Lo que falta:**
- NO hay instrucciones explÃ­citas de "NO INVENTES"
- NO hay validaciÃ³n contra el texto fuente
- NO hay advertencia sobre usar conocimiento previo

---

## âœ… SoluciÃ³n Propuesta

### ModificaciÃ³n del Prompt (Agregar ANTES del contenido)

Insertar estas instrucciones **CRÃTICAS** al inicio del prompt (despuÃ©s de la lÃ­nea 873):

```typescript
const optimizedPrompt = `Eres Jarvis, el asistente editorial de Pachuca Noticias...

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš ï¸ REGLAS CRÃTICAS DE FIDELIDAD FACTUAL (LEE PRIMERO)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ PRINCIPIO FUNDAMENTAL - SOURCE GROUNDING:
â€¢ USA ÃšNICAMENTE informaciÃ³n explÃ­citamente presente en el CONTENIDO DE LA NOTICIA proporcionado
â€¢ Si la noticia dice "presidenta", escribe "presidenta" (NO "jefa de gobierno")
â€¢ Si la noticia dice "alcalde", escribe "alcalde" (NO "presidente municipal")
â€¢ COPIA EXACTAMENTE los tÃ­tulos, cargos, y nombres tal como aparecen en el input

âŒ PROHIBICIONES ABSOLUTAS:
1. NO uses tu conocimiento previo o memoria de entrenamiento
2. NO hagas suposiciones sobre cargos, fechas, o contextos
3. NO infiera informaciÃ³n que no estÃ¡ explÃ­citamente en el texto
4. NO "corrijas" informaciÃ³n del texto original aunque creas que estÃ¡ mal
5. NO agregues datos histÃ³ricos que no estÃ¡n en la noticia
6. NO uses informaciÃ³n de tu cutoff de entrenamiento

âœ… OBLIGACIONES ESTRICTAS:
1. VERIFICA cada nombre propio contra el texto original
2. CONFIRMA cada cargo o tÃ­tulo exactamente como aparece
3. USA las fechas y nÃºmeros tal cual estÃ¡n en el input
4. MANTÃ‰N la terminologÃ­a exacta del texto fuente
5. SI dudas de un detalle, revisa el input nuevamente

ğŸ” PROCESO DE VERIFICACIÃ“N (APLICA SIEMPRE):
Antes de generar cada pÃ¡rrafo:
1. Â¿Este hecho estÃ¡ textualmente en el input? â†’ âœ… Ãšsalo / âŒ DescÃ¡rtalo
2. Â¿Estoy usando el cargo/tÃ­tulo exacto del input? â†’ Verificar
3. Â¿Estoy agregando contexto de mi entrenamiento? â†’ âŒ PROHIBIDO

ğŸ“‹ EJEMPLOS DE FIDELIDAD:

CORRECTO âœ…:
Input: "La presidenta Claudia Sheinbaum declarÃ³..."
Output: "La presidenta Claudia Sheinbaum declarÃ³..."

INCORRECTO âŒ:
Input: "La presidenta Claudia Sheinbaum declarÃ³..."
Output: "La jefa de Gobierno Claudia Sheinbaum declarÃ³..." â† PROHIBIDO

CORRECTO âœ…:
Input: "El secretario de Marina, Raymundo Morales..."
Output: "El secretario de Marina, Raymundo Morales..."

INCORRECTO âŒ:
Input: "El secretario de Marina, Raymundo Morales..."
Output: "El almirante Raymundo Morales..." â† PROHIBIDO

âš¡ REGLA DE ORO:
"Cuando hay conflicto entre tu conocimiento y el texto, el texto SIEMPRE gana"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

<thinking>
Voy a procesar esta noticia siguiendo estos pasos:
1. Extraer TODOS los hechos relevantes del input SIN AGREGAR NADA
2. Identificar personajes, fechas, lugares, cifras, declaraciones TAL COMO ESTÃN
3. VERIFICAR cada elemento contra el texto original antes de usarlo
4. Determinar mÃºltiples Ã¡ngulos editoriales posibles BASADOS EN EL TEXTO
5. Crear tÃ­tulo ÃšNICO y CREATIVO usando tÃ©cnicas de variaciÃ³n
6. Desarrollar contenido EXTENSO y DETALLADO PERO FIEL A LA FUENTE
7. Generar keywords y tags basados en el contenido real
8. Crear copys sociales con hooks Ãºnicos y llamativos
</thinking>

ğŸ¯ REGLAS CRÃTICAS PARA TÃTULOS:
...
[resto del prompt actual]
```

---

## ğŸ”§ ImplementaciÃ³n

### Paso 1: Modificar el archivo

Editar: `packages/api-nueva/src/content-ai/services/content-generation.service.ts`

**LÃ­nea ~873** - MÃ©todo `preparePromptFromTemplate()`

Agregar la secciÃ³n de "REGLAS CRÃTICAS DE FIDELIDAD FACTUAL" inmediatamente despuÃ©s de:
```typescript
const optimizedPrompt = `Eres Jarvis, el asistente editorial de Pachuca Noticias...
```

### Paso 2: Agregar validaciÃ³n post-generaciÃ³n (opcional pero recomendado)

Agregar un mÃ©todo de verificaciÃ³n despuÃ©s de `parseAndValidateResponse()`:

```typescript
/**
 * ğŸ” Verificar fidelidad factual del contenido generado
 */
private verifyFactualFidelity(
  generatedContent: string,
  originalContent: string
): { isValid: boolean; warnings: string[] } {
  const warnings: string[] = [];

  // Extraer nombres propios del original
  const originalNames = this.extractProperNouns(originalContent);
  const generatedNames = this.extractProperNouns(generatedContent);

  // Verificar que los nombres/cargos no hayan cambiado
  for (const originalName of originalNames) {
    const found = generatedNames.some(genName =>
      genName.toLowerCase().includes(originalName.toLowerCase())
    );

    if (!found) {
      warnings.push(`Posible alucinaciÃ³n: "${originalName}" del original no encontrado en generado`);
    }
  }

  return {
    isValid: warnings.length === 0,
    warnings
  };
}

private extractProperNouns(text: string): string[] {
  // Regex simple para nombres propios (capitalizaciÃ³n)
  const regex = /\b[A-ZÃ‘ÃÃ‰ÃÃ“Ãš][a-zÃ±Ã¡Ã©Ã­Ã³ÃºÃ¼]+(?:\s+[A-ZÃ‘ÃÃ‰ÃÃ“Ãš][a-zÃ±Ã¡Ã©Ã­Ã³ÃºÃ¼]+)*\b/g;
  return text.match(regex) || [];
}
```

### Paso 3: Testing

Probar con casos problemÃ¡ticos:

```bash
# Test 1: Cargo correcto (presidenta vs jefa de gobierno)
# Test 2: Fechas actuales vs conocimiento histÃ³rico
# Test 3: Nombres exactos sin modificaciÃ³n
```

---

## ğŸ“ˆ Resultados Esperados

### Antes (Con bug):
```
Input: "La presidenta Claudia Sheinbaum..."
Output: "La jefa de Gobierno de la Ciudad de MÃ©xico, Claudia Sheinbaum..." âŒ
```

### DespuÃ©s (Corregido):
```
Input: "La presidenta Claudia Sheinbaum..."
Output: "La presidenta Claudia Sheinbaum..." âœ…
```

---

## ğŸ”— Referencias

1. **Prompt Engineering Methods to Reduce Hallucinations (2025)**
   - Source-Aware Prompting
   - Chain-of-Verification (CoVe)
   - Reflective Prompting

2. **OpenAI Best Practices**
   - "Answer based only on the text below"
   - Explicit instruction to avoid knowledge base

3. **Lakera AI - LLM Hallucinations Guide 2025**
   - Grounding techniques
   - Verification strategies

---

## â° Prioridad de ImplementaciÃ³n

**ALTA** - Este bug afecta la credibilidad del contenido generado

**Impacto:**
- ğŸ”´ DesinformaciÃ³n a usuarios
- ğŸ”´ PÃ©rdida de confianza
- ğŸŸ¡ MÃ¡s trabajo de revisiÃ³n manual

**Esfuerzo estimado:** 2-3 horas
- 1 hora: ModificaciÃ³n del prompt
- 1 hora: Testing exhaustivo
- 30 min: ValidaciÃ³n con casos reales

---

## ğŸ“ Notas Adicionales

El modelo actual (GPT-4o-mini con cutoff 2018) es especialmente vulnerable a este tipo de errores con informaciÃ³n polÃ­tica reciente. Las instrucciones explÃ­citas de grounding son CRÃTICAS para este caso de uso.

**Alternativa a largo plazo:** Considerar upgrade a modelo con cutoff mÃ¡s reciente (GPT-4 Turbo 2024+) que tenga contexto de Sheinbaum como presidenta.
