# üîç An√°lisis: Mejoramiento del Sistema de Extracci√≥n Autom√°tica de Noticias

**Fecha de An√°lisis**: 15 de Octubre, 2025
**Autor**: Jarvis (Claude Code)
**Objetivo**: Implementar sistema robusto de extracci√≥n autom√°tica de URLs con scheduling inteligente, detecci√≥n de duplicados y logs detallados

---

## ‚ö†Ô∏è ACLARACI√ìN CR√çTICA: Problema Identificado

### üî¥ **PROBLEMA PRINCIPAL**: Scheduling No Considera √öltima Extracci√≥n al Iniciar

#### **Estado Actual del Sistema**
El sistema de extracci√≥n autom√°tica tiene dos implementaciones diferentes con problemas similares:

1. **`GeneratorProSchedulerService`** (Cron cada 5 minutos)
   - ‚úÖ Calcula correctamente `nextRun` basado en `lastExtractionRun + extractionFrequency`
   - ‚ùå **PROBLEMA**: Actualiza `lastExtractionRun` INMEDIATAMENTE al encolar, no al ejecutar
   - ‚ùå **PROBLEMA**: NO tiene l√≥gica en `OnModuleInit` para calcular pr√≥xima ejecuci√≥n
   - ‚ùå **PROBLEMA**: Espera a que el cron ejecute (puede tardar hasta 5 minutos despu√©s de arrancar)

2. **`GeneratorProOrchestratorService`** (setInterval)
   - ‚ùå **PROBLEMA CR√çTICO**: Usa `setInterval` directo desde el inicio del m√≥dulo
   - ‚ùå **PROBLEMA**: NO considera `lastExtractionRun` al programar primera ejecuci√≥n
   - ‚ùå **PROBLEMA**: Si `lastExtractionRun` fue hace 30 min y `extractionFrequency` es 60 min, deber√≠a ejecutar en 30 min, NO en 60 min

#### **Ejemplo del Problema**:
```
Escenario:
- lastExtractionRun: 3:00 PM
- extractionFrequency: 60 minutos (cada hora)
- Servidor se levanta a las: 3:45 PM

‚ùå COMPORTAMIENTO ACTUAL:
- GeneratorProSchedulerService: Espera hasta 3:50 PM (pr√≥ximo cron), luego verifica y ejecuta
- GeneratorProOrchestratorService: Programa en 60 minutos desde NOW (4:45 PM)

‚úÖ COMPORTAMIENTO ESPERADO:
- Calcular nextRun = 3:00 PM + 60 min = 4:00 PM
- Como NOW = 3:45 PM, programar en 15 minutos (a las 4:00 PM)
```

#### **Otros Problemas Identificados**:

3. **Detecci√≥n de URLs Duplicadas**
   - ‚ùå NO hay sistema para trackear URLs extra√≠das previamente
   - ‚ùå NO hay schema para guardar URLs procesadas
   - ‚ùå Cada extracci√≥n vuelve a procesar TODAS las URLs del listado

4. **Logs de Extracci√≥n Incompletos**
   - ‚úÖ Existe `NoticiasExtractionLog` para contenido extra√≠do
   - ‚ùå NO hay logs de URLs extra√≠das desde listados
   - ‚ùå NO hay tracking de cu√°ntas URLs nuevas vs duplicadas

5. **Sincronizaci√≥n de Timestamps**
   - ‚ùå `lastExtractionRun` se actualiza al ENCOLAR job, no al EJECUTAR
   - ‚ùå Si job falla, `lastExtractionRun` ya fue actualizado incorrectamente

---

## üìã TABLA DE CONTENIDOS

1. [Estado Actual del Sistema](#-1-estado-actual-del-sistema)
2. [Arquitectura Propuesta](#-2-arquitectura-propuesta)
3. [Esquemas y Servicios](#-3-esquemas-y-servicios)
4. [Patrones de Implementaci√≥n](#-4-patrones-de-implementacion)
5. [Fases de Implementaci√≥n](#-5-fases-de-implementacion)
6. [S√≠ntesis Ejecutiva de Fases](#-6-sintesis-ejecutiva-de-fases)

---

## üîç 1. ESTADO ACTUAL DEL SISTEMA

### 1.1. Schema: `NewsWebsiteConfig`

**Archivo**: `packages/api-nueva/src/generator-pro/schemas/news-website-config.schema.ts`

```typescript
@Schema({ timestamps: true })
export class NewsWebsiteConfig {
  @Prop({ required: true, unique: true, trim: true })
  name: string; // "El Universal", "Milenio"

  @Prop({ required: true, trim: true })
  listingUrl: string; // URL donde est√°n todas las noticias

  // üìã SELECTORES PARA LISTADO
  @Prop({ type: Object, required: true })
  listingSelectors: {
    articleLinks: string; // CSS selector para URLs
    titleSelector?: string;
    imageSelector?: string;
  };

  // ‚è∞ CONFIGURACI√ìN DE FRECUENCIAS
  @Prop({ default: 60 })
  extractionFrequency: number; // Frecuencia en minutos (60 = cada hora)

  // üìä CONTROL DE EJECUCI√ìN
  @Prop()
  lastExtractionRun?: Date; // üî¥ PROBLEMA: Se actualiza al encolar, no al ejecutar

  @Prop({ type: Object, default: {} })
  statistics: {
    totalUrlsExtracted?: number;
    successfulExtractions?: number;
    failedExtractions?: number;
    lastExtractionAt?: Date;
  };
}

// üßÆ VIRTUAL para siguiente ejecuci√≥n
NewsWebsiteConfigSchema.virtual('nextExtractionDue').get(function () {
  if (!this.lastExtractionRun) return new Date();
  return new Date(this.lastExtractionRun.getTime() + (this.extractionFrequency * 60 * 1000));
});
```

**‚úÖ Lo que funciona bien**:
- Tiene campo `extractionFrequency` para configurar cada cu√°nto extraer
- Tiene virtual `nextExtractionDue` que calcula pr√≥xima ejecuci√≥n
- Tiene estad√≠sticas de extracci√≥n

**üî¥ Problemas**:
- `lastExtractionRun` se actualiza al encolar job, no al completar
- NO hay campo para guardar URLs extra√≠das (para detecci√≥n de duplicados)
- NO hay logs espec√≠ficos de extracci√≥n de URLs

---

### 1.2. Service: `GeneratorProSchedulerService`

**Archivo**: `packages/api-nueva/src/generator-pro/services/generator-pro-scheduler.service.ts`

```typescript
@Injectable()
export class GeneratorProSchedulerService implements OnModuleInit {
  onModuleInit() {
    this.logger.log('GeneratorProScheduler initialized');
    // üî¥ PROBLEMA: NO hay l√≥gica aqu√≠ para calcular pr√≥ximas ejecuciones
  }

  /**
   * ‚è∞ Cron que ejecuta cada 5 minutos
   */
  @Cron('*/5 * * * *')
  async scheduleExtractionJobs() {
    const websites = await this.websiteModel.find({ isActive: true });

    for (const website of websites) {
      const nextRun = this.calculateNextRun(
        website.lastExtractionRun,
        website.extractionFrequency,
      );

      // ‚úÖ BIEN: Verifica si ya es tiempo de ejecutar
      if (Date.now() >= nextRun.getTime()) {
        await this.queueService.addExtractionJob({
          type: 'extract_urls',
          websiteConfigId: String(website._id),
          data: { automated: true },
        });

        // üî¥ PROBLEMA: Actualiza INMEDIATAMENTE, no al completar job
        await this.websiteModel.findByIdAndUpdate(website._id, {
          lastExtractionRun: new Date(),
        });
      }
    }
  }

  /**
   * ‚úÖ BIEN: Calcula pr√≥xima ejecuci√≥n
   */
  private calculateNextRun(lastRun: Date | undefined, frequencyMinutes: number): Date {
    if (!lastRun) {
      return new Date(0); // Ejecutar ahora
    }
    return new Date(lastRun.getTime() + (frequencyMinutes * 60 * 1000));
  }
}
```

**‚úÖ Lo que funciona bien**:
- C√°lculo correcto de `nextRun`
- Cron cada 5 minutos verifica sitios

**üî¥ Problemas**:
1. **NO hay l√≥gica en `OnModuleInit`**: Al levantar servidor, espera hasta 5 minutos para que el cron ejecute
2. **Actualizaci√≥n prematura**: `lastExtractionRun` se actualiza al encolar, no al ejecutar el job
3. **Sin considerar estado actual**: Si debi√≥ ejecutar hace 10 minutos, no ejecuta inmediatamente

---

### 1.3. Service: `GeneratorProOrchestratorService`

**Archivo**: `packages/api-nueva/src/generator-pro/services/generator-pro-orchestrator.service.ts`

```typescript
@Injectable()
export class GeneratorProOrchestratorService {
  private cycleIntervals: Map<string, NodeJS.Timeout> = new Map();

  /**
   * üîÑ Inicializa ciclos para un sitio
   */
  private async initializeWebsiteCycles(website: NewsWebsiteConfigDocument): Promise<void> {
    // üî¥ PROBLEMA CR√çTICO: setInterval desde NOW, no considera lastExtractionRun
    const extractionInterval = setInterval(async () => {
      if (this.isSystemRunning) {
        await this.runExtractionCycle(String(website._id));
      }
    }, website.extractionFrequency * 60 * 1000); // Empieza a contar desde NOW

    this.cycleIntervals.set(`${website._id}-extraction`, extractionInterval);
  }

  /**
   * Ejecuta ciclo de extracci√≥n
   */
  async runExtractionCycle(websiteId: string): Promise<CycleResult> {
    const website = await this.websiteConfigModel.findById(websiteId);

    // Extraer URLs
    const extractedUrls = await this.websiteService.extractNewsUrls(websiteId);

    // üî¥ PROBLEMA: NO hay detecci√≥n de URLs duplicadas
    for (const url of extractedUrls) {
      await this.queueService.addExtractionJob({
        type: 'extract_content',
        websiteConfigId: websiteId,
        data: { targetUrl: url },
      });
    }

    // üî¥ PROBLEMA: Actualiza timestamp aqu√≠, pero ¬øqu√© pasa si hubo error?
    await this.websiteConfigModel.findByIdAndUpdate(websiteId, {
      lastExtractionRun: new Date(),
    });

    return { success: true, jobsCreated: extractedUrls.length };
  }
}
```

**üî¥ Problemas cr√≠ticos**:
1. **`setInterval` desde NOW**: NO calcula cu√°ndo deber√≠a ser la pr√≥xima ejecuci√≥n basado en `lastExtractionRun`
2. **Sin detecci√≥n de duplicados**: Procesa todas las URLs cada vez, incluso las ya procesadas
3. **Actualizaci√≥n incondicional**: Actualiza `lastExtractionRun` aunque no se hayan extra√≠do URLs nuevas

---

### 1.4. Schema: `NoticiasExtractionLog`

**Archivo**: `packages/api-nueva/src/noticias/schemas/noticias-extraction-log.schema.ts`

```typescript
@Schema({ timestamps: true })
export class NoticiasExtractionLog {
  @Prop({ required: true, trim: true })
  sourceUrl: string; // URL de la noticia individual

  @Prop({ required: true, trim: true })
  domain: string;

  @Prop({ enum: ['success', 'error', 'partial', 'skipped'], required: true })
  status: string;

  @Prop({ required: true })
  method: 'cheerio' | 'puppeteer' | 'manual';

  @Prop({ required: true })
  processingTime: number; // ms

  @Prop({ type: Object })
  extractedData?: {
    title?: string;
    contentLength?: number;
    imagesCount?: number;
  };

  @Prop({ type: Object })
  error?: {
    message: string;
    type: 'network' | 'parsing' | 'selector' | 'timeout' | 'rate_limit' | 'unknown';
  };

  // ... m√°s campos
}
```

**‚úÖ Lo que funciona bien**:
- Logs detallados de extracci√≥n de contenido
- M√©tricas de performance
- Tracking de errores

**üî¥ Problema**:
- Solo logs de extracci√≥n de CONTENIDO
- NO hay logs de extracci√≥n de URLs desde listados

---

## üèóÔ∏è 2. ARQUITECTURA PROPUESTA

### 2.1. Schema Nuevo: `ExtractedUrlTracking`

**Archivo**: `packages/api-nueva/src/generator-pro/schemas/extracted-url-tracking.schema.ts`

```typescript
import { Prop, Schema, SchemaFactory } from '@nestjs/mongoose';
import { Document, Types } from 'mongoose';

export type ExtractedUrlTrackingDocument = ExtractedUrlTracking & Document;

/**
 * üîó Schema para trackear URLs extra√≠das y evitar duplicados
 *
 * Prop√≥sito:
 * - Guardar todas las URLs extra√≠das de listados
 * - Detectar URLs duplicadas
 * - Trackear estado de procesamiento de cada URL
 * - Permitir re-extracci√≥n despu√©s de X d√≠as (contenido actualizado)
 */
@Schema({ timestamps: true })
export class ExtractedUrlTracking {
  // ========================================
  // üîë IDENTIFICACI√ìN
  // ========================================

  @Prop({ required: true, type: Types.ObjectId, ref: 'NewsWebsiteConfig', index: true })
  websiteConfigId: Types.ObjectId; // Sitio del que se extrajo

  @Prop({ required: true, trim: true, index: true })
  url: string; // URL completa de la noticia

  @Prop({ required: true, trim: true, index: true })
  urlHash: string; // Hash SHA-256 de la URL (para b√∫squedas r√°pidas)

  @Prop({ required: true, trim: true })
  domain: string; // Dominio extra√≠do de la URL

  // ========================================
  // üìä ESTADO DE PROCESAMIENTO
  // ========================================

  @Prop({
    required: true,
    enum: ['discovered', 'queued', 'processing', 'completed', 'failed', 'skipped'],
    default: 'discovered',
    index: true
  })
  status: 'discovered' | 'queued' | 'processing' | 'completed' | 'failed' | 'skipped';

  @Prop()
  queuedAt?: Date; // Cu√°ndo se agreg√≥ a la cola

  @Prop()
  processedAt?: Date; // Cu√°ndo se proces√≥ completamente

  @Prop({ type: String })
  failureReason?: string; // Raz√≥n de fallo si status = 'failed'

  // ========================================
  // üîç METADATA DE EXTRACCI√ìN
  // ========================================

  @Prop({ required: true })
  firstDiscoveredAt: Date; // Primera vez que se descubri√≥

  @Prop({ required: true })
  lastSeenAt: Date; // √öltima vez que apareci√≥ en el listado

  @Prop({ default: 1 })
  timesDiscovered: number; // Cu√°ntas veces ha aparecido en listados

  @Prop({ type: String })
  title?: string; // T√≠tulo si se pudo extraer del listado

  @Prop({ type: String })
  imageUrl?: string; // Imagen si se pudo extraer del listado

  // ========================================
  // üîÑ CONTROL DE RE-EXTRACCI√ìN
  // ========================================

  @Prop({ default: false })
  allowReExtraction: boolean; // ¬øPermitir re-extraer despu√©s de X d√≠as?

  @Prop({ default: 30 })
  reExtractionDays: number; // D√≠as despu√©s de los cuales se puede re-extraer (default: 30)

  @Prop()
  nextReExtractionAllowedAt?: Date; // Cu√°ndo se permite re-extraer

  // ========================================
  // üìù REFERENCIAS
  // ========================================

  @Prop({ type: Types.ObjectId, ref: 'ExtractedNoticia' })
  extractedNoticiaId?: Types.ObjectId; // Referencia a contenido extra√≠do (si existe)

  @Prop({ type: Types.ObjectId, ref: 'AIContentGeneration' })
  generatedContentId?: Types.ObjectId; // Referencia a contenido generado (si existe)

  @Prop({ type: Types.ObjectId, ref: 'PublishedNoticia' })
  publishedNoticiaId?: Types.ObjectId; // Referencia a noticia publicada (si existe)

  // ========================================
  // üìä M√âTRICAS
  // ========================================

  @Prop({ default: 0 })
  extractionAttempts: number; // Intentos de extracci√≥n

  @Prop()
  lastExtractionAttempt?: Date;

  @Prop({ type: Number })
  processingTime?: number; // Tiempo de procesamiento (ms)

  // ========================================
  // üîß METADATA
  // ========================================

  @Prop({ default: Date.now })
  createdAt: Date;

  @Prop({ default: Date.now })
  updatedAt: Date;
}

export const ExtractedUrlTrackingSchema = SchemaFactory.createForClass(ExtractedUrlTracking);

// ========================================
// üìá √çNDICES
// ========================================

// √çndice √∫nico: Un sitio no puede tener la misma URL dos veces
ExtractedUrlTrackingSchema.index(
  { websiteConfigId: 1, urlHash: 1 },
  { unique: true }
);

// √çndices de b√∫squeda
ExtractedUrlTrackingSchema.index({ url: 1 });
ExtractedUrlTrackingSchema.index({ domain: 1, status: 1 });
ExtractedUrlTrackingSchema.index({ status: 1, createdAt: -1 });
ExtractedUrlTrackingSchema.index({ websiteConfigId: 1, status: 1, lastSeenAt: -1 });

// √çndice para re-extracci√≥n
ExtractedUrlTrackingSchema.index({
  status: 1,
  allowReExtraction: 1,
  nextReExtractionAllowedAt: 1
});

// ========================================
// üîß M√âTODOS
// ========================================

ExtractedUrlTrackingSchema.methods.markAsQueued = function (): Promise<ExtractedUrlTrackingDocument> {
  this.status = 'queued';
  this.queuedAt = new Date();
  return this.save();
};

ExtractedUrlTrackingSchema.methods.markAsProcessing = function (): Promise<ExtractedUrlTrackingDocument> {
  this.status = 'processing';
  this.extractionAttempts += 1;
  this.lastExtractionAttempt = new Date();
  return this.save();
};

ExtractedUrlTrackingSchema.methods.markAsCompleted = function (
  extractedNoticiaId?: Types.ObjectId,
  processingTime?: number
): Promise<ExtractedUrlTrackingDocument> {
  this.status = 'completed';
  this.processedAt = new Date();
  if (extractedNoticiaId) {
    this.extractedNoticiaId = extractedNoticiaId;
  }
  if (processingTime) {
    this.processingTime = processingTime;
  }
  // Calcular pr√≥xima re-extracci√≥n si est√° habilitada
  if (this.allowReExtraction) {
    this.nextReExtractionAllowedAt = new Date(
      Date.now() + this.reExtractionDays * 24 * 60 * 60 * 1000
    );
  }
  return this.save();
};

ExtractedUrlTrackingSchema.methods.markAsFailed = function (reason: string): Promise<ExtractedUrlTrackingDocument> {
  this.status = 'failed';
  this.failureReason = reason;
  this.processedAt = new Date();
  return this.save();
};

ExtractedUrlTrackingSchema.methods.updateLastSeen = function (): Promise<ExtractedUrlTrackingDocument> {
  this.lastSeenAt = new Date();
  this.timesDiscovered += 1;
  return this.save();
};
```

---

### 2.2. Schema Nuevo: `UrlExtractionLog`

**Archivo**: `packages/api-nueva/src/generator-pro/schemas/url-extraction-log.schema.ts`

```typescript
import { Prop, Schema, SchemaFactory } from '@nestjs/mongoose';
import { Document, Types } from 'mongoose';

export type UrlExtractionLogDocument = UrlExtractionLog & Document;

/**
 * üìä Schema para logs de extracci√≥n de URLs desde listados
 *
 * Prop√≥sito:
 * - Loggear cada ejecuci√≥n de extracci√≥n de URLs
 * - Trackear cu√°ntas URLs se encontraron
 * - Trackear cu√°ntas URLs son nuevas vs duplicadas
 * - M√©tricas de performance
 * - Debugging de selectores
 */
@Schema({ timestamps: true })
export class UrlExtractionLog {
  // ========================================
  // üîë IDENTIFICACI√ìN
  // ========================================

  @Prop({ required: true, type: Types.ObjectId, ref: 'NewsWebsiteConfig', index: true })
  websiteConfigId: Types.ObjectId;

  @Prop({ required: true, trim: true })
  websiteName: string; // Nombre del sitio para b√∫squedas f√°ciles

  @Prop({ required: true, trim: true })
  listingUrl: string; // URL del listado escaneado

  // ========================================
  // üìä RESULTADOS
  // ========================================

  @Prop({ required: true, enum: ['success', 'partial', 'failed'], index: true })
  status: 'success' | 'partial' | 'failed';

  @Prop({ required: true, default: 0 })
  totalUrlsFound: number; // Total de URLs encontradas en el listado

  @Prop({ required: true, default: 0 })
  newUrls: number; // URLs nuevas (no vistas antes)

  @Prop({ required: true, default: 0 })
  duplicateUrls: number; // URLs que ya exist√≠an

  @Prop({ required: true, default: 0 })
  skippedUrls: number; // URLs que se saltaron (filtros, etc)

  @Prop({ required: true, default: 0 })
  queuedUrls: number; // URLs agregadas a la cola de procesamiento

  // ========================================
  // ‚è±Ô∏è M√âTRICAS DE PERFORMANCE
  // ========================================

  @Prop({ required: true })
  processingTime: number; // Tiempo total (ms)

  @Prop()
  fetchTime?: number; // Tiempo de fetch del listado (ms)

  @Prop()
  parsingTime?: number; // Tiempo de parsing con Cheerio/Puppeteer (ms)

  @Prop()
  dbOperationsTime?: number; // Tiempo de operaciones de BD (ms)

  // ========================================
  // üîç METADATA T√âCNICA
  // ========================================

  @Prop({ required: true, enum: ['cheerio', 'puppeteer'] })
  method: 'cheerio' | 'puppeteer';

  @Prop({ required: true })
  httpStatusCode: number;

  @Prop({ type: String })
  selector: string; // Selector usado (articleLinks)

  @Prop()
  htmlSize?: number; // Tama√±o del HTML descargado (bytes)

  // ========================================
  // ‚ùå ERRORES Y WARNINGS
  // ========================================

  @Prop({ type: String })
  errorMessage?: string;

  @Prop({ type: String })
  errorType?: 'network' | 'parsing' | 'selector' | 'timeout' | 'rate_limit' | 'unknown';

  @Prop({ type: [String], default: [] })
  warnings: string[]; // Warnings no cr√≠ticos

  // ========================================
  // üìù SAMPLES PARA DEBUGGING
  // ========================================

  @Prop({ type: [String], default: [] })
  sampleUrls: string[]; // Primeras 5 URLs encontradas (para debugging)

  // ========================================
  // üîß METADATA
  // ========================================

  @Prop({ default: false })
  wasScheduled: boolean; // ¬øFue ejecuci√≥n autom√°tica o manual?

  @Prop({ required: true })
  executedAt: Date; // Cu√°ndo se ejecut√≥

  @Prop({ default: Date.now })
  createdAt: Date;
}

export const UrlExtractionLogSchema = SchemaFactory.createForClass(UrlExtractionLog);

// ========================================
// üìá √çNDICES
// ========================================

UrlExtractionLogSchema.index({ websiteConfigId: 1, executedAt: -1 });
UrlExtractionLogSchema.index({ status: 1, executedAt: -1 });
UrlExtractionLogSchema.index({ websiteName: 1, executedAt: -1 });
UrlExtractionLogSchema.index({ executedAt: -1 }); // Para queries de rango temporal
```

---

## üõ†Ô∏è 3. ESQUEMAS Y SERVICIOS

### 3.1. Service Nuevo: `SmartExtractionSchedulerService`

**Archivo**: `packages/api-nueva/src/generator-pro/services/smart-extraction-scheduler.service.ts`

```typescript
import { Injectable, Logger, OnModuleInit } from '@nestjs/common';
import { InjectModel } from '@nestjs/mongoose';
import { SchedulerRegistry } from '@nestjs/schedule';
import { Model, Types } from 'mongoose';
import { CronJob } from 'cron';
import { EventEmitter2 } from '@nestjs/event-emitter';
import { NewsWebsiteConfig, NewsWebsiteConfigDocument } from '../schemas/news-website-config.schema';
import { UrlExtractionService } from './url-extraction.service';

/**
 * üìÖ Smart Extraction Scheduler Service
 *
 * PROP√ìSITO:
 * - Scheduling inteligente de extracci√≥n de URLs
 * - Considera √∫ltima extracci√≥n al levantar servidor
 * - Programa pr√≥xima ejecuci√≥n bas√°ndose en frecuencia configurada
 * - Actualiza timestamps solo despu√©s de ejecuci√≥n exitosa
 *
 * FUNCIONAMIENTO:
 * 1. OnModuleInit: Calcula pr√≥ximas ejecuciones para todos los sitios activos
 * 2. Programa CronJobs din√°micos para cada sitio
 * 3. Despu√©s de cada extracci√≥n, re-programa la siguiente
 */
@Injectable()
export class SmartExtractionSchedulerService implements OnModuleInit {
  private readonly logger = new Logger(SmartExtractionSchedulerService.name);
  private readonly scheduledJobs: Map<string, CronJob> = new Map();

  constructor(
    @InjectModel(NewsWebsiteConfig.name)
    private websiteModel: Model<NewsWebsiteConfigDocument>,
    private schedulerRegistry: SchedulerRegistry,
    private urlExtractionService: UrlExtractionService,
    private eventEmitter: EventEmitter2,
  ) {}

  /**
   * üöÄ Inicializa scheduling al levantar el servidor
   */
  async onModuleInit(): Promise<void> {
    this.logger.log('üöÄ Inicializando Smart Extraction Scheduler...');

    try {
      const activeWebsites = await this.websiteModel.find({ isActive: true });

      if (activeWebsites.length === 0) {
        this.logger.warn('‚ö†Ô∏è No hay sitios activos configurados');
        return;
      }

      for (const website of activeWebsites) {
        await this.scheduleWebsiteExtraction(website);
      }

      this.logger.log(
        `‚úÖ Scheduler iniciado con ${activeWebsites.length} sitios activos`,
      );
    } catch (error) {
      this.logger.error(
        `‚ùå Error inicializando scheduler: ${error.message}`,
        error.stack,
      );
    }
  }

  /**
   * üìÖ Programa extracci√≥n para un sitio espec√≠fico
   *
   * L√ìGICA:
   * 1. Calcula cu√°ndo DEBER√çA ejecutar pr√≥xima extracci√≥n
   * 2. Si ya pas√≥ la hora, ejecuta INMEDIATAMENTE
   * 3. Si no, programa para la hora calculada
   * 4. Usa SchedulerRegistry para CronJobs din√°micos
   */
  async scheduleWebsiteExtraction(
    website: NewsWebsiteConfigDocument,
  ): Promise<void> {
    const websiteId = String(website._id);
    const now = Date.now();

    // Calcular pr√≥xima ejecuci√≥n
    const nextExecutionTime = this.calculateNextExecution(
      website.lastExtractionRun,
      website.extractionFrequency,
    );

    const delayMs = nextExecutionTime.getTime() - now;

    this.logger.log(
      `üìÖ Programando extracci√≥n para "${website.name}":`,
    );
    this.logger.log(
      `   - √öltima extracci√≥n: ${website.lastExtractionRun ? website.lastExtractionRun.toISOString() : 'NUNCA'}`,
    );
    this.logger.log(
      `   - Frecuencia: ${website.extractionFrequency} minutos`,
    );
    this.logger.log(
      `   - Pr√≥xima ejecuci√≥n calculada: ${nextExecutionTime.toISOString()}`,
    );
    this.logger.log(
      `   - Delay: ${Math.floor(delayMs / 1000)} segundos`,
    );

    // Si ya debi√≥ ejecutarse, ejecutar INMEDIATAMENTE
    if (delayMs <= 0) {
      this.logger.log(
        `‚ö° Extracci√≥n de "${website.name}" ya debi√≥ ejecutarse, ejecutando AHORA`,
      );
      await this.executeExtraction(websiteId);
      return;
    }

    // Programar para la hora calculada
    this.scheduleOneTimeExecution(websiteId, delayMs);
  }

  /**
   * ‚è∞ Programa una ejecuci√≥n √∫nica despu√©s de X ms
   *
   * Despu√©s de ejecutar, re-programa la siguiente
   */
  private scheduleOneTimeExecution(
    websiteId: string,
    delayMs: number,
  ): void {
    // Limpiar job anterior si existe
    this.cancelScheduledJob(websiteId);

    // Programar timeout
    const timeout = setTimeout(async () => {
      await this.executeExtraction(websiteId);
    }, delayMs);

    // Guardar referencia (como pseudo-CronJob para poder cancelar)
    const pseudoJob = {
      stop: () => clearTimeout(timeout),
      start: () => {},
    } as any;

    this.scheduledJobs.set(websiteId, pseudoJob);

    this.logger.log(
      `‚úÖ Programada extracci√≥n para ${websiteId} en ${Math.floor(delayMs / 1000)} segundos`,
    );
  }

  /**
   * üîç Ejecuta extracci√≥n y re-programa siguiente
   */
  private async executeExtraction(websiteId: string): Promise<void> {
    this.logger.log(`üîç Ejecutando extracci√≥n para sitio: ${websiteId}`);

    try {
      // Ejecutar extracci√≥n
      const result = await this.urlExtractionService.extractUrls(
        new Types.ObjectId(websiteId),
      );

      if (result.success) {
        // ‚úÖ CR√çTICO: Solo actualizar timestamp DESPU√âS de ejecuci√≥n exitosa
        await this.websiteModel.findByIdAndUpdate(websiteId, {
          lastExtractionRun: new Date(),
          $inc: {
            'statistics.successfulExtractions': 1,
            'statistics.totalUrlsExtracted': result.totalUrlsFound,
          },
        });

        this.logger.log(
          `‚úÖ Extracci√≥n exitosa para ${websiteId}: ${result.newUrls} URLs nuevas`,
        );
      } else {
        // Error: NO actualizar timestamp, intentar de nuevo en pr√≥xima ejecuci√≥n
        this.logger.error(
          `‚ùå Extracci√≥n fall√≥ para ${websiteId}: ${result.error}`,
        );

        await this.websiteModel.findByIdAndUpdate(websiteId, {
          $inc: { 'statistics.failedExtractions': 1 },
        });
      }

      // Re-programar siguiente extracci√≥n
      const website = await this.websiteModel.findById(websiteId);
      if (website && website.isActive) {
        await this.scheduleWebsiteExtraction(website);
      }

      // Emitir evento
      this.eventEmitter.emit('url-extraction.completed', {
        websiteId,
        success: result.success,
        newUrls: result.newUrls,
        totalUrls: result.totalUrlsFound,
        timestamp: new Date(),
      });
    } catch (error) {
      this.logger.error(
        `‚ùå Error ejecutando extracci√≥n para ${websiteId}: ${error.message}`,
        error.stack,
      );

      // Re-programar de todos modos
      const website = await this.websiteModel.findById(websiteId);
      if (website && website.isActive) {
        await this.scheduleWebsiteExtraction(website);
      }
    }
  }

  /**
   * üßÆ Calcula pr√≥xima ejecuci√≥n bas√°ndose en √∫ltima y frecuencia
   *
   * L√ìGICA:
   * - Si nunca se ha ejecutado: AHORA
   * - Si ya se ejecut√≥: lastRun + frequencyMinutes
   */
  private calculateNextExecution(
    lastRun: Date | undefined,
    frequencyMinutes: number,
  ): Date {
    if (!lastRun) {
      // Nunca se ha ejecutado, ejecutar ahora
      return new Date();
    }

    // Calcular pr√≥xima ejecuci√≥n
    const nextRun = new Date(
      lastRun.getTime() + frequencyMinutes * 60 * 1000,
    );

    return nextRun;
  }

  /**
   * ‚ùå Cancela job programado para un sitio
   */
  private cancelScheduledJob(websiteId: string): void {
    const existingJob = this.scheduledJobs.get(websiteId);
    if (existingJob) {
      existingJob.stop();
      this.scheduledJobs.delete(websiteId);
      this.logger.debug(`Cancelado job anterior para ${websiteId}`);
    }
  }

  /**
   * üîÑ Re-programa extracci√≥n para un sitio (√∫til para cambios de config)
   */
  async rescheduleWebsite(websiteId: string): Promise<void> {
    this.cancelScheduledJob(websiteId);

    const website = await this.websiteModel.findById(websiteId);
    if (!website) {
      throw new Error(`Website ${websiteId} not found`);
    }

    if (!website.isActive) {
      this.logger.log(`Sitio ${websiteId} est√° inactivo, no se programa`);
      return;
    }

    await this.scheduleWebsiteExtraction(website);
  }

  /**
   * ‚è∏Ô∏è Pausa extracci√≥n para un sitio
   */
  async pauseWebsite(websiteId: string): Promise<void> {
    this.cancelScheduledJob(websiteId);
    await this.websiteModel.findByIdAndUpdate(websiteId, {
      isActive: false,
    });
    this.logger.log(`‚è∏Ô∏è Extracci√≥n pausada para ${websiteId}`);
  }

  /**
   * ‚ñ∂Ô∏è Reanuda extracci√≥n para un sitio
   */
  async resumeWebsite(websiteId: string): Promise<void> {
    const website = await this.websiteModel.findByIdAndUpdate(
      websiteId,
      { isActive: true },
      { new: true },
    );

    if (!website) {
      throw new Error(`Website ${websiteId} not found`);
    }

    await this.scheduleWebsiteExtraction(website);
    this.logger.log(`‚ñ∂Ô∏è Extracci√≥n reanudada para ${websiteId}`);
  }

  /**
   * üîç Obtiene estado de scheduling para un sitio
   */
  async getSchedulingStatus(websiteId: string): Promise<{
    isScheduled: boolean;
    nextExecution: Date | null;
    lastExecution: Date | null;
    frequency: number;
  }> {
    const website = await this.websiteModel.findById(websiteId);
    if (!website) {
      throw new Error(`Website ${websiteId} not found`);
    }

    const isScheduled = this.scheduledJobs.has(websiteId) && website.isActive;
    const nextExecution = isScheduled
      ? this.calculateNextExecution(
          website.lastExtractionRun,
          website.extractionFrequency,
        )
      : null;

    return {
      isScheduled,
      nextExecution,
      lastExecution: website.lastExtractionRun || null,
      frequency: website.extractionFrequency,
    };
  }
}
```

---

### 3.2. Service Nuevo: `UrlExtractionService`

**Archivo**: `packages/api-nueva/src/generator-pro/services/url-extraction.service.ts`

```typescript
import { Injectable, Logger } from '@nestjs/common';
import { InjectModel } from '@nestjs/mongoose';
import { Model, Types } from 'mongoose';
import axios from 'axios';
import * as cheerio from 'cheerio';
import { createHash } from 'crypto';

import { NewsWebsiteConfig, NewsWebsiteConfigDocument } from '../schemas/news-website-config.schema';
import { ExtractedUrlTracking, ExtractedUrlTrackingDocument } from '../schemas/extracted-url-tracking.schema';
import { UrlExtractionLog, UrlExtractionLogDocument } from '../schemas/url-extraction-log.schema';
import { PuppeteerManagerService } from '../../modules/reports/services/puppeteer-manager.service';

/**
 * üîç URL Extraction Service
 *
 * Responsabilidades:
 * - Extraer URLs desde listados de sitios web
 * - Detectar URLs duplicadas
 * - Guardar tracking de URLs extra√≠das
 * - Generar logs detallados
 * - Encolar URLs nuevas para extracci√≥n de contenido
 */

interface UrlExtractionResult {
  success: boolean;
  totalUrlsFound: number;
  newUrls: number;
  duplicateUrls: number;
  skippedUrls: number;
  queuedUrls: number;
  processingTime: number;
  error?: string;
}

@Injectable()
export class UrlExtractionService {
  private readonly logger = new Logger(UrlExtractionService.name);

  constructor(
    @InjectModel(NewsWebsiteConfig.name)
    private websiteModel: Model<NewsWebsiteConfigDocument>,
    @InjectModel(ExtractedUrlTracking.name)
    private urlTrackingModel: Model<ExtractedUrlTrackingDocument>,
    @InjectModel(UrlExtractionLog.name)
    private urlLogModel: Model<UrlExtractionLogDocument>,
    private puppeteerService: PuppeteerManagerService,
  ) {}

  /**
   * üîç Extrae URLs de un sitio web
   */
  async extractUrls(websiteId: Types.ObjectId): Promise<UrlExtractionResult> {
    const startTime = Date.now();

    this.logger.log(`üîç Iniciando extracci√≥n de URLs para sitio: ${websiteId}`);

    try {
      // Obtener configuraci√≥n del sitio
      const website = await this.websiteModel.findById(websiteId);
      if (!website) {
        throw new Error(`Website ${websiteId} not found`);
      }

      if (!website.isActive) {
        throw new Error(`Website ${website.name} is not active`);
      }

      // Extraer URLs seg√∫n m√©todo (Cheerio o Puppeteer)
      const extractedUrls = website.extractionSettings.useJavaScript
        ? await this.extractWithPuppeteer(website)
        : await this.extractWithCheerio(website);

      // Procesar URLs extra√≠das
      const processingResult = await this.processExtractedUrls(
        website,
        extractedUrls,
      );

      const processingTime = Date.now() - startTime;

      // Crear log
      await this.createExtractionLog(website, {
        status: 'success',
        totalUrlsFound: extractedUrls.length,
        newUrls: processingResult.newUrls,
        duplicateUrls: processingResult.duplicateUrls,
        skippedUrls: processingResult.skippedUrls,
        queuedUrls: processingResult.queuedUrls,
        processingTime,
        method: website.extractionSettings.useJavaScript ? 'puppeteer' : 'cheerio',
        sampleUrls: extractedUrls.slice(0, 5),
      });

      this.logger.log(
        `‚úÖ Extracci√≥n completada para ${website.name}: ${processingResult.newUrls} nuevas, ${processingResult.duplicateUrls} duplicadas`,
      );

      return {
        success: true,
        totalUrlsFound: extractedUrls.length,
        newUrls: processingResult.newUrls,
        duplicateUrls: processingResult.duplicateUrls,
        skippedUrls: processingResult.skippedUrls,
        queuedUrls: processingResult.queuedUrls,
        processingTime,
      };
    } catch (error) {
      const processingTime = Date.now() - startTime;

      this.logger.error(
        `‚ùå Error extrayendo URLs para ${websiteId}: ${error.message}`,
        error.stack,
      );

      // Crear log de error
      const website = await this.websiteModel.findById(websiteId);
      if (website) {
        await this.createExtractionLog(website, {
          status: 'failed',
          totalUrlsFound: 0,
          newUrls: 0,
          duplicateUrls: 0,
          skippedUrls: 0,
          queuedUrls: 0,
          processingTime,
          errorMessage: error.message,
          errorType: this.categorizeError(error.message),
        });
      }

      return {
        success: false,
        totalUrlsFound: 0,
        newUrls: 0,
        duplicateUrls: 0,
        skippedUrls: 0,
        queuedUrls: 0,
        processingTime,
        error: error.message,
      };
    }
  }

  /**
   * üåê Extrae URLs con Cheerio (est√°tico)
   */
  private async extractWithCheerio(
    website: NewsWebsiteConfigDocument,
  ): Promise<string[]> {
    this.logger.log(`üï∑Ô∏è Extrayendo URLs con Cheerio desde: ${website.listingUrl}`);

    try {
      // Fetch HTML
      const response = await axios.get(website.listingUrl, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
          ...website.customHeaders,
        },
        timeout: website.extractionSettings.timeout || 30000,
      });

      // Parse con Cheerio
      const $ = cheerio.load(response.data);

      // Extraer URLs usando selector
      const selector = website.listingSelectors.articleLinks;
      const urls: string[] = [];

      $(selector).each((_, element) => {
        const href = $(element).attr('href');
        if (href) {
          // Convertir a URL absoluta si es relativa
          const absoluteUrl = this.makeAbsoluteUrl(href, website.baseUrl);
          urls.push(absoluteUrl);
        }
      });

      this.logger.log(`üîó Encontradas ${urls.length} URLs con selector "${selector}"`);

      return urls;
    } catch (error) {
      this.logger.error(`‚ùå Error con Cheerio: ${error.message}`);
      throw error;
    }
  }

  /**
   * üé≠ Extrae URLs con Puppeteer (din√°mico)
   */
  private async extractWithPuppeteer(
    website: NewsWebsiteConfigDocument,
  ): Promise<string[]> {
    this.logger.log(`üé≠ Extrayendo URLs con Puppeteer desde: ${website.listingUrl}`);

    try {
      // Renderizar con Puppeteer
      const html = await this.puppeteerService.getRenderedHTML(
        website.listingUrl,
        {
          waitTime: website.extractionSettings.waitTime,
          timeout: website.extractionSettings.timeout || 30000,
          useJavaScript: true,
        },
      );

      // Parse con Cheerio
      const $ = cheerio.load(html);

      // Extraer URLs
      const selector = website.listingSelectors.articleLinks;
      const urls: string[] = [];

      $(selector).each((_, element) => {
        const href = $(element).attr('href');
        if (href) {
          const absoluteUrl = this.makeAbsoluteUrl(href, website.baseUrl);
          urls.push(absoluteUrl);
        }
      });

      this.logger.log(`üîó Encontradas ${urls.length} URLs con Puppeteer`);

      return urls;
    } catch (error) {
      this.logger.error(`‚ùå Error con Puppeteer: ${error.message}`);
      throw error;
    }
  }

  /**
   * üîÑ Procesa URLs extra√≠das
   *
   * L√ìGICA:
   * 1. Para cada URL, calcular hash
   * 2. Verificar si ya existe en ExtractedUrlTracking
   * 3. Si existe: actualizar lastSeenAt
   * 4. Si no existe: crear nuevo tracking y encolar para extracci√≥n
   */
  private async processExtractedUrls(
    website: NewsWebsiteConfigDocument,
    urls: string[],
  ): Promise<{
    newUrls: number;
    duplicateUrls: number;
    skippedUrls: number;
    queuedUrls: number;
  }> {
    let newUrls = 0;
    let duplicateUrls = 0;
    let skippedUrls = 0;
    let queuedUrls = 0;

    for (const url of urls) {
      try {
        // Calcular hash de la URL
        const urlHash = this.calculateUrlHash(url);

        // Buscar si ya existe
        const existingTracking = await this.urlTrackingModel.findOne({
          websiteConfigId: website._id,
          urlHash,
        });

        if (existingTracking) {
          // URL duplicada: actualizar lastSeenAt
          await existingTracking.updateLastSeen();
          duplicateUrls++;

          this.logger.debug(`üîÅ URL duplicada: ${url}`);

          // Verificar si necesita re-extracci√≥n
          if (this.needsReExtraction(existingTracking)) {
            this.logger.log(`üîÑ URL necesita re-extracci√≥n: ${url}`);
            // TODO: Encolar para re-extracci√≥n
            queuedUrls++;
          }
        } else {
          // URL nueva: crear tracking
          const tracking = new this.urlTrackingModel({
            websiteConfigId: website._id,
            url,
            urlHash,
            domain: new URL(url).hostname,
            status: 'discovered',
            firstDiscoveredAt: new Date(),
            lastSeenAt: new Date(),
            timesDiscovered: 1,
            allowReExtraction: false, // Por defecto no permitir re-extracci√≥n
          });

          await tracking.save();
          newUrls++;

          this.logger.debug(`üÜï URL nueva: ${url}`);

          // Encolar para extracci√≥n de contenido
          // TODO FASE 2: Integrar con GeneratorProQueueService
          queuedUrls++;
        }
      } catch (error) {
        this.logger.error(`‚ùå Error procesando URL ${url}: ${error.message}`);
        skippedUrls++;
      }
    }

    return {
      newUrls,
      duplicateUrls,
      skippedUrls,
      queuedUrls,
    };
  }

  /**
   * üîë Calcula hash SHA-256 de una URL
   */
  private calculateUrlHash(url: string): string {
    return createHash('sha256').update(url).digest('hex');
  }

  /**
   * üîó Convierte URL relativa a absoluta
   */
  private makeAbsoluteUrl(href: string, baseUrl: string): string {
    try {
      if (href.startsWith('http://') || href.startsWith('https://')) {
        return href;
      }
      const base = new URL(baseUrl);
      return new URL(href, base.origin).href;
    } catch {
      return href;
    }
  }

  /**
   * üîÑ Verifica si una URL necesita re-extracci√≥n
   */
  private needsReExtraction(tracking: ExtractedUrlTrackingDocument): boolean {
    if (!tracking.allowReExtraction) {
      return false;
    }

    if (!tracking.nextReExtractionAllowedAt) {
      return false;
    }

    return new Date() >= tracking.nextReExtractionAllowedAt;
  }

  /**
   * üìù Crea log de extracci√≥n
   */
  private async createExtractionLog(
    website: NewsWebsiteConfigDocument,
    data: Partial<UrlExtractionLog>,
  ): Promise<void> {
    try {
      const log = new this.urlLogModel({
        websiteConfigId: website._id,
        websiteName: website.name,
        listingUrl: website.listingUrl,
        selector: website.listingSelectors.articleLinks,
        executedAt: new Date(),
        wasScheduled: true,
        ...data,
      });

      await log.save();
    } catch (error) {
      this.logger.error(`Error creando log: ${error.message}`);
    }
  }

  /**
   * üîç Categoriza tipo de error
   */
  private categorizeError(errorMessage: string): string {
    const message = errorMessage.toLowerCase();

    if (message.includes('timeout')) return 'timeout';
    if (message.includes('network') || message.includes('connection')) return 'network';
    if (message.includes('selector') || message.includes('not found')) return 'selector';
    if (message.includes('rate limit')) return 'rate_limit';
    if (message.includes('parse')) return 'parsing';

    return 'unknown';
  }
}
```

---

## üõ†Ô∏è 4. PATRONES DE IMPLEMENTACI√ìN

### 4.1. Patrones del Backend (NestJS)

#### ‚úÖ **Patr√≥n 1: OnModuleInit para Scheduling Inteligente**

```typescript
// ‚úÖ BIEN: Calcular pr√≥xima ejecuci√≥n al iniciar
@Injectable()
export class SmartScheduler implements OnModuleInit {
  async onModuleInit() {
    const websites = await this.websiteModel.find({ isActive: true });

    for (const website of websites) {
      // Calcular cu√°ndo deber√≠a ejecutar
      const nextRun = this.calculateNextRun(
        website.lastExtractionRun,
        website.extractionFrequency
      );

      // Programar con delay calculado
      const delay = nextRun.getTime() - Date.now();

      if (delay <= 0) {
        // Ya debi√≥ ejecutarse, ejecutar AHORA
        await this.executeExtraction(website._id);
      } else {
        // Programar para la hora calculada
        this.scheduleExtraction(website._id, delay);
      }
    }
  }
}

// ‚ùå MAL: No considerar √∫ltima ejecuci√≥n
@Injectable()
export class BadScheduler implements OnModuleInit {
  async onModuleInit() {
    // Solo loggear, no programar nada
    this.logger.log('Initialized');
  }
}
```

#### ‚úÖ **Patr√≥n 2: SchedulerRegistry para Cron Jobs Din√°micos**

```typescript
// ‚úÖ BIEN: Usar SchedulerRegistry para jobs din√°micos
import { SchedulerRegistry } from '@nestjs/schedule';

@Injectable()
export class SmartScheduler {
  constructor(private schedulerRegistry: SchedulerRegistry) {}

  scheduleExtraction(websiteId: string, delayMs: number) {
    // Programar timeout din√°mico
    const timeout = setTimeout(async () => {
      await this.executeExtraction(websiteId);
    }, delayMs);

    // Registrar para poder cancelar despu√©s
    this.schedulerRegistry.addTimeout(`extraction-${websiteId}`, timeout);
  }

  cancelExtraction(websiteId: string) {
    this.schedulerRegistry.deleteTimeout(`extraction-${websiteId}`);
  }
}

// ‚ùå MAL: setInterval directo sin considerar estado
@Injectable()
export class BadScheduler {
  initializeWebsite(website: Website) {
    // Empieza a contar desde NOW, ignora lastRun
    setInterval(() => {
      this.extract(website._id);
    }, website.frequency * 60 * 1000);
  }
}
```

#### ‚úÖ **Patr√≥n 3: Actualizar Timestamps DESPU√âS de Ejecuci√≥n**

```typescript
// ‚úÖ BIEN: Actualizar despu√©s de √©xito
async executeExtraction(websiteId: string) {
  try {
    const result = await this.extractUrls(websiteId);

    if (result.success) {
      // Solo actualizar si fue exitoso
      await this.websiteModel.findByIdAndUpdate(websiteId, {
        lastExtractionRun: new Date(),
      });
    }

    // Re-programar siguiente
    await this.scheduleNextExtraction(websiteId);

  } catch (error) {
    // NO actualizar timestamp si hubo error
    this.logger.error(`Error: ${error.message}`);
  }
}

// ‚ùå MAL: Actualizar ANTES de ejecutar
async scheduleExtraction(websiteId: string) {
  // Actualiza timestamp ANTES de ejecutar
  await this.websiteModel.findByIdAndUpdate(websiteId, {
    lastExtractionRun: new Date(),
  });

  // Si esto falla, timestamp ya fue actualizado incorrectamente
  await this.extractUrls(websiteId);
}
```

#### ‚úÖ **Patr√≥n 4: Tipado Estricto (No `any`)**

```typescript
// ‚úÖ BIEN: Tipos expl√≠citos
interface UrlExtractionResult {
  success: boolean;
  totalUrlsFound: number;
  newUrls: number;
  duplicateUrls: number;
  error?: string;
}

async extractUrls(websiteId: Types.ObjectId): Promise<UrlExtractionResult> {
  // Implementaci√≥n
}

// ‚ùå MAL: Uso de any
async extractUrls(websiteId: any): Promise<any> {
  // Pierde validaci√≥n de tipos
}
```

#### ‚úÖ **Patr√≥n 5: EventEmitter para Desacoplar M√≥dulos**

```typescript
// ‚úÖ BIEN: Emitir eventos para comunicaci√≥n
@Injectable()
export class UrlExtractionService {
  constructor(private eventEmitter: EventEmitter2) {}

  async extractUrls(websiteId: string) {
    const result = await this.doExtraction(websiteId);

    // Emitir evento
    this.eventEmitter.emit('url-extraction.completed', {
      websiteId,
      newUrls: result.newUrls,
      success: result.success,
    });

    return result;
  }
}

// Otro servicio escucha
@Injectable()
export class GeneratorProQueueService {
  constructor(private eventEmitter: EventEmitter2) {
    this.eventEmitter.on('url-extraction.completed', this.handleUrlExtraction.bind(this));
  }

  async handleUrlExtraction(payload) {
    // Encolar URLs para extracci√≥n de contenido
  }
}

// ‚ùå MAL: Inyecci√≥n circular con forwardRef
@Injectable()
export class UrlExtractionService {
  constructor(
    @Inject(forwardRef(() => GeneratorProQueueService))
    private queueService: GeneratorProQueueService
  ) {}
}
```

---

## üöÄ 5. FASES DE IMPLEMENTACI√ìN

### FASE 0: Preparaci√≥n y Schemas ‚úÖ

**Objetivo**: Crear schemas necesarios para tracking de URLs y logs

**Archivos a crear**:
1. `packages/api-nueva/src/generator-pro/schemas/extracted-url-tracking.schema.ts`
2. `packages/api-nueva/src/generator-pro/schemas/url-extraction-log.schema.ts`

**Tareas**:
- [x] Crear `ExtractedUrlTracking` schema con campos:
  - `websiteConfigId`, `url`, `urlHash`
  - `status`: discovered | queued | processing | completed | failed | skipped
  - `firstDiscoveredAt`, `lastSeenAt`, `timesDiscovered`
  - `allowReExtraction`, `reExtractionDays`, `nextReExtractionAllowedAt`
  - Referencias: `extractedNoticiaId`, `generatedContentId`, `publishedNoticiaId`
- [x] Crear `UrlExtractionLog` schema con campos:
  - `websiteConfigId`, `websiteName`, `listingUrl`
  - `status`, `totalUrlsFound`, `newUrls`, `duplicateUrls`, `queuedUrls`
  - M√©tricas: `processingTime`, `fetchTime`, `parsingTime`
  - `errorMessage`, `errorType`, `warnings`, `sampleUrls`
- [x] Definir √≠ndices correctos para ambos schemas
- [x] Definir m√©todos helper en schemas

**Validaci√≥n**:
- Schemas compilan sin errores TypeScript
- √çndices definidos correctamente
- No uso de `any`

---

### FASE 1: Service de Extracci√≥n de URLs

**Objetivo**: Crear servicio que extrae URLs desde listados con detecci√≥n de duplicados

**Archivos a crear**:
1. `packages/api-nueva/src/generator-pro/services/url-extraction.service.ts`

**Tareas**:
- [ ] Crear `UrlExtractionService` con m√©todo `extractUrls(websiteId)`
- [ ] Implementar `extractWithCheerio(website)` para extracci√≥n est√°tica
- [ ] Implementar `extractWithPuppeteer(website)` para extracci√≥n din√°mica
- [ ] Implementar `processExtractedUrls(website, urls)`:
  - Calcular hash de cada URL
  - Buscar en `ExtractedUrlTracking` por hash
  - Si existe: actualizar `lastSeenAt`, incrementar `timesDiscovered`
  - Si no existe: crear nuevo tracking con status `discovered`
  - Retornar contadores: newUrls, duplicateUrls, skippedUrls
- [ ] Implementar `createExtractionLog()` para guardar log detallado
- [ ] Manejo de errores con categorizaci√≥n
- [ ] Helpers: `calculateUrlHash()`, `makeAbsoluteUrl()`, `needsReExtraction()`

**Validaci√≥n**:
- Extrae URLs correctamente con Cheerio
- Extrae URLs correctamente con Puppeteer
- Detecta URLs duplicadas
- Crea tracking para URLs nuevas
- Actualiza `lastSeenAt` para URLs existentes
- Genera logs detallados
- No uso de `any`

---

### FASE 2: Smart Extraction Scheduler

**Objetivo**: Implementar scheduler inteligente que considera √∫ltima extracci√≥n al iniciar

**Archivos a crear**:
1. `packages/api-nueva/src/generator-pro/services/smart-extraction-scheduler.service.ts`

**Tareas**:
- [ ] Crear `SmartExtractionSchedulerService` que implementa `OnModuleInit`
- [ ] Implementar `onModuleInit()`:
  - Cargar todos los sitios activos
  - Para cada sitio, calcular pr√≥xima ejecuci√≥n con `calculateNextExecution()`
  - Si `nextExecution <= NOW`: ejecutar inmediatamente
  - Si `nextExecution > NOW`: programar con delay calculado
- [ ] Implementar `calculateNextExecution(lastRun, frequency)`:
  - Si `lastRun` es `undefined`: retornar `NOW`
  - Si `lastRun` existe: retornar `lastRun + frequency`
- [ ] Implementar `scheduleOneTimeExecution(websiteId, delayMs)`:
  - Usar `setTimeout` con delay calculado
  - Guardar referencia en `Map<string, NodeJS.Timeout>`
  - Al ejecutar, llamar `executeExtraction()` y re-programar siguiente
- [ ] Implementar `executeExtraction(websiteId)`:
  - Llamar `urlExtractionService.extractUrls()`
  - Si exitoso: actualizar `lastExtractionRun` en BD
  - Si falla: NO actualizar timestamp
  - Re-programar siguiente ejecuci√≥n
  - Emitir evento `url-extraction.completed`
- [ ] M√©todos auxiliares:
  - `rescheduleWebsite(websiteId)`: para cambios de config
  - `pauseWebsite(websiteId)`: cancelar scheduling
  - `resumeWebsite(websiteId)`: reactivar scheduling
  - `getSchedulingStatus(websiteId)`: obtener estado

**Validaci√≥n**:
- Al levantar servidor, calcula correctamente pr√≥ximas ejecuciones
- Si `lastRun` fue hace 30 min y frequency es 60 min, programa en 30 min
- Si `lastRun` fue hace 70 min y frequency es 60 min, ejecuta inmediatamente
- Actualiza `lastExtractionRun` solo despu√©s de ejecuci√≥n exitosa
- Re-programa correctamente despu√©s de cada ejecuci√≥n
- No uso de `any`, sin `forwardRef`

---

### FASE 3: Integraci√≥n con M√≥dulo GeneratorPro

**Objetivo**: Integrar nuevos servicios con m√≥dulo existente

**Archivos a modificar**:
1. `packages/api-nueva/src/generator-pro/generator-pro.module.ts`

**Tareas**:
- [ ] Agregar schemas al `MongooseModule.forFeature()`:
  - `ExtractedUrlTracking`
  - `UrlExtractionLog`
- [ ] Agregar servicios a `providers`:
  - `UrlExtractionService`
  - `SmartExtractionSchedulerService`
- [ ] Agregar a `exports` si otros m√≥dulos lo necesitan
- [ ] Deprecar o remover `GeneratorProSchedulerService` (cron cada 5 min)
- [ ] Deprecar `GeneratorProOrchestratorService.initializeWebsiteCycles()` (setInterval)

**Validaci√≥n**:
- M√≥dulo compila sin errores
- Servicios se inyectan correctamente
- No hay dependencias circulares
- `npm run build` ejecuta sin errores

---

### FASE 4: Controller y Endpoints REST

**Objetivo**: Exponer endpoints para gesti√≥n manual de extracci√≥n

**Archivos a crear/modificar**:
1. `packages/api-nueva/src/generator-pro/controllers/extraction-management.controller.ts`

**Tareas**:
- [ ] Crear `ExtractionManagementController`
- [ ] Endpoints:
  ```typescript
  POST /generator-pro/extraction/trigger/:websiteId
  // Forzar extracci√≥n inmediata

  GET /generator-pro/extraction/status/:websiteId
  // Obtener estado de scheduling

  POST /generator-pro/extraction/pause/:websiteId
  // Pausar extracci√≥n autom√°tica

  POST /generator-pro/extraction/resume/:websiteId
  // Reanudar extracci√≥n autom√°tica

  POST /generator-pro/extraction/reschedule/:websiteId
  // Re-calcular y re-programar

  GET /generator-pro/extraction/logs/:websiteId
  // Obtener logs de extracci√≥n

  GET /generator-pro/extraction/urls/:websiteId
  // Obtener URLs trackeadas
  ```
- [ ] Validaci√≥n con DTOs
- [ ] Guards: `JwtAuthGuard`
- [ ] Documentaci√≥n Swagger

**Validaci√≥n**:
- Endpoints responden correctamente
- Validaci√≥n de par√°metros funciona
- Autenticaci√≥n requerida
- Documentaci√≥n Swagger generada

---

### FASE 5: Deprecaci√≥n de C√≥digo Antiguo

**Objetivo**: Remover o deprecar implementaciones antiguas

**Archivos a modificar**:
1. `packages/api-nueva/src/generator-pro/services/generator-pro-scheduler.service.ts`
2. `packages/api-nueva/src/generator-pro/services/generator-pro-orchestrator.service.ts`

**Tareas**:
- [ ] Deprecar `GeneratorProSchedulerService.scheduleExtractionJobs()`
  - Agregar decorator `@Deprecated()`
  - Loggear warning si se usa
  - Documentar migraci√≥n a `SmartExtractionSchedulerService`
- [ ] Deprecar `GeneratorProOrchestratorService.initializeWebsiteCycles()`
  - Agregar decorator `@Deprecated()`
  - Documentar nueva implementaci√≥n
- [ ] Crear gu√≠a de migraci√≥n en `docs/migration-extraction-scheduler.md`
- [ ] Actualizar README con nueva arquitectura

**Validaci√≥n**:
- C√≥digo antiguo marcado como deprecated
- Documentaci√≥n de migraci√≥n completa
- No breaking changes para usuarios existentes

---

## üìä 6. S√çNTESIS EJECUTIVA DE FASES

### Resumen de Implementaci√≥n

| Fase | Descripci√≥n | Archivos Nuevos | Archivos Modificados | Estimaci√≥n |
|------|-------------|-----------------|----------------------|------------|
| **FASE 0** | Schemas de tracking y logs | 2 schemas | 0 | 2 horas |
| **FASE 1** | Service de extracci√≥n de URLs | 1 service | 0 | 4 horas |
| **FASE 2** | Smart Extraction Scheduler | 1 service | 0 | 6 horas |
| **FASE 3** | Integraci√≥n con m√≥dulo | 0 | 1 module | 1 hora |
| **FASE 4** | Controller y endpoints | 1 controller | 0 | 3 horas |
| **FASE 5** | Deprecaci√≥n c√≥digo antiguo | 1 doc | 2 services | 2 horas |
| **TOTAL** | ‚Äî | **5 archivos** | **3 archivos** | **18 horas** |

---

### Problemas Resueltos

‚úÖ **Problema 1: Scheduling no considera √∫ltima extracci√≥n al iniciar**
- **Soluci√≥n**: `SmartExtractionSchedulerService` con `onModuleInit()` que calcula pr√≥xima ejecuci√≥n bas√°ndose en `lastExtractionRun + frequency`
- **Resultado**: Si servidor se levanta a las 3:45 PM y √∫ltima extracci√≥n fue a las 3:00 PM con frequency 60 min, programa en 15 minutos (4:00 PM), NO en 60 minutos

‚úÖ **Problema 2: Actualizaci√≥n prematura de timestamps**
- **Soluci√≥n**: Actualizar `lastExtractionRun` solo DESPU√âS de ejecuci√≥n exitosa, no al encolar
- **Resultado**: Si extracci√≥n falla, timestamp no se actualiza incorrectamente

‚úÖ **Problema 3: Sin detecci√≥n de URLs duplicadas**
- **Soluci√≥n**: `ExtractedUrlTracking` schema con `urlHash` √∫nico por sitio
- **Resultado**: Sistema detecta URLs ya procesadas y no las vuelve a encolar

‚úÖ **Problema 4: Logs incompletos**
- **Soluci√≥n**: `UrlExtractionLog` schema con m√©tricas detalladas
- **Resultado**: Logs muestran: total URLs, nuevas, duplicadas, skipped, tiempo de procesamiento, errores

‚úÖ **Problema 5: setInterval desde NOW**
- **Soluci√≥n**: Usar `setTimeout` din√°mico con delay calculado basado en `lastRun`
- **Resultado**: Scheduling preciso que respeta frecuencias configuradas

---

### Beneficios de la Nueva Arquitectura

1. **‚è±Ô∏è Scheduling Preciso**
   - Considera √∫ltima extracci√≥n al calcular pr√≥xima
   - No pierde sincronizaci√≥n al reiniciar servidor
   - Ejecuta inmediatamente si ya pas√≥ la hora

2. **üîç Detecci√≥n de Duplicados**
   - Trackea todas las URLs extra√≠das
   - Evita procesar URLs ya vistas
   - Permite re-extracci√≥n configurableafter X d√≠as

3. **üìä Logs Detallados**
   - Historial completo de extracciones
   - M√©tricas de performance
   - Debugging de selectores
   - Estad√≠sticas de URLs nuevas vs duplicadas

4. **üîß Control Manual**
   - Endpoints REST para gesti√≥n
   - Pausar/reanudar extracci√≥n
   - Forzar extracci√≥n inmediata
   - Consultar estado y logs

5. **üèóÔ∏è C√≥digo Limpio**
   - Sin `any` types
   - Sin `forwardRef()`
   - EventEmitter para comunicaci√≥n
   - Tipado estricto TypeScript

---

### Diagrama de Flujo Propuesto

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. SERVIDOR SE LEVANTA (OnModuleInit)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. SmartExtractionSchedulerService.onModuleInit()              ‚îÇ
‚îÇ    - Cargar sitios activos                                      ‚îÇ
‚îÇ    - Para cada sitio: calcular nextExecution                    ‚îÇ
‚îÇ      nextExecution = lastExtractionRun + extractionFrequency    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
                    ¬ønextExecution <= NOW?
                         ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ S√ç                              ‚îÇ NO
        ‚îÇ                                 ‚îÇ
        ‚ñº                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Ejecutar AHORA    ‚îÇ          ‚îÇ Programar setTimeout ‚îÇ
‚îÇ                   ‚îÇ          ‚îÇ con delay calculado  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                                    ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. UrlExtractionService.extractUrls()                          ‚îÇ
‚îÇ    - Fetch listingUrl (Cheerio o Puppeteer)                    ‚îÇ
‚îÇ    - Extraer URLs con selector                                  ‚îÇ
‚îÇ    - Para cada URL: calcular hash                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Procesar URLs Extra√≠das                                     ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ    ‚îÇ Para cada URL:                               ‚îÇ            ‚îÇ
‚îÇ    ‚îÇ   - Buscar en ExtractedUrlTracking por hash  ‚îÇ            ‚îÇ
‚îÇ    ‚îÇ   - Si existe:                                ‚îÇ            ‚îÇ
‚îÇ    ‚îÇ     * Actualizar lastSeenAt                   ‚îÇ            ‚îÇ
‚îÇ    ‚îÇ     * Incrementar timesDiscovered             ‚îÇ            ‚îÇ
‚îÇ    ‚îÇ     * Verificar si necesita re-extracci√≥n     ‚îÇ            ‚îÇ
‚îÇ    ‚îÇ   - Si NO existe:                             ‚îÇ            ‚îÇ
‚îÇ    ‚îÇ     * Crear nuevo tracking                    ‚îÇ            ‚îÇ
‚îÇ    ‚îÇ     * Status = discovered                     ‚îÇ            ‚îÇ
‚îÇ    ‚îÇ     * Encolar para extracci√≥n de contenido    ‚îÇ            ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. Guardar Log y Actualizar Timestamp                          ‚îÇ
‚îÇ    - Crear UrlExtractionLog con:                                ‚îÇ
‚îÇ      * totalUrlsFound, newUrls, duplicateUrls                   ‚îÇ
‚îÇ      * processingTime, sampleUrls                               ‚îÇ
‚îÇ    - Si exitoso:                                                 ‚îÇ
‚îÇ      * Actualizar NewsWebsiteConfig.lastExtractionRun = NOW     ‚îÇ
‚îÇ    - Si fall√≥:                                                   ‚îÇ
‚îÇ      * NO actualizar timestamp                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. Re-Programar Siguiente Extracci√≥n                           ‚îÇ
‚îÇ    - Calcular nuevo nextExecution:                              ‚îÇ
‚îÇ      nextExecution = NOW + extractionFrequency                   ‚îÇ
‚îÇ    - Programar setTimeout con delay calculado                    ‚îÇ
‚îÇ    - Emitir evento: url-extraction.completed                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Ejemplo Concreto

**Escenario**:
- Sitio: "El Universal"
- `extractionFrequency`: 60 minutos
- `lastExtractionRun`: 14:00
- Servidor se levanta: 14:45

**Flujo con NUEVA arquitectura**:

```
14:45:00 - Servidor arranca
14:45:01 - SmartExtractionSchedulerService.onModuleInit()
14:45:01 - Calcula nextExecution = 14:00 + 60 min = 15:00
14:45:01 - Delay = 15:00 - 14:45 = 15 minutos
14:45:01 - Programa setTimeout(15 min)
14:45:01 - Log: "Programada extracci√≥n para 'El Universal' en 15 minutos (15:00)"

15:00:00 - setTimeout ejecuta
15:00:01 - UrlExtractionService.extractUrls()
15:00:02 - Extrae 50 URLs del listado
15:00:03 - Procesa URLs: 10 nuevas, 40 duplicadas
15:00:04 - Encola 10 URLs nuevas para extracci√≥n de contenido
15:00:05 - Crea UrlExtractionLog con m√©tricas
15:00:06 - Actualiza lastExtractionRun = 15:00
15:00:07 - Calcula nextExecution = 15:00 + 60 min = 16:00
15:00:08 - Programa setTimeout(60 min)
15:00:09 - Emite evento: url-extraction.completed

16:00:00 - Repite ciclo...
```

**Comparaci√≥n con arquitectura ANTIGUA**:

```
‚ùå ANTIGUA (GeneratorProSchedulerService con cron cada 5 min):
14:45:00 - Servidor arranca
14:45:01 - onModuleInit() solo loggea, no programa nada
14:50:00 - Cron ejecuta (5 min despu√©s)
14:50:01 - Verifica: nextRun = 14:00 + 60 = 15:00, NOW = 14:50
14:50:01 - No ejecuta porque 14:50 < 15:00
14:55:00 - Cron ejecuta
14:55:01 - No ejecuta porque 14:55 < 15:00
15:00:00 - Cron ejecuta
15:00:01 - Ejecuta porque NOW >= 15:00
15:00:02 - Actualiza lastExtractionRun = 15:00 INMEDIATAMENTE (antes de ejecutar)
15:00:03 - Si extracci√≥n falla, timestamp ya fue actualizado incorrectamente
```

---

### Conclusi√≥n

La nueva arquitectura resuelve todos los problemas identificados mediante:

1. **Scheduling inteligente** con `onModuleInit()` que calcula pr√≥ximas ejecuciones
2. **Timestamps precisos** actualizados solo despu√©s de ejecuci√≥n exitosa
3. **Detecci√≥n de duplicados** con `ExtractedUrlTracking`
4. **Logs detallados** con `UrlExtractionLog`
5. **C√≥digo limpio** sin `any`, sin `forwardRef`, con EventEmitter

**Estimaci√≥n total**: 18 horas de desarrollo

**Pr√≥ximos pasos**: Aprobar fases y comenzar implementaci√≥n en orden secuencial.

---

**Fin del An√°lisis** üìã
